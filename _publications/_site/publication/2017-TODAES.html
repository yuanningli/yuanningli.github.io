<p>In this article, we develop several novel algorithms to train classifiers that can be implemented on chip with low-power fixed-point arithmetic with extremely small word length. These algorithms are based on Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), and Logistic Regression (LR), and are referred to as LDA-FP, SVM-FP, and LR-FP, respectively. They incorporate the nonidealities (i.e., rounding and overflow) associated with fixed-point arithmetic into the offline training process so that the resulting classifiers are robust to these nonidealities. Mathematically, LDA-FP, SVM-FP, and LR-FP are formulated as mixed integer programming problems that can be robustly solved by the branch-and-bound methods described in this article. Our numerical experiments demonstrate that LDA-FP, SVM-FP, and LR-FP substantially outperform the conventional approaches for the emerging biomedical applications of brain decoding.</p>

<p><a href="/files/2017_TODAES.pdf">Download paper here</a></p>

<p>Citation: Hassan Albalawi, Yuanning Li, and Xin Li. “Training Fixed-Point Classifiers for On-Chip Low-Power Implementation.” <i>ACM Transactions on Design Automation of Electronic Systems (TODAES)</i>, 22, no. 4 (2017): 69.</p>

